% Default mode is landscape, which is what we want, however dvips and
% a0poster do not quite do the right thing, so we end up with text in
% landscape style (wide and short) down a portrait page (narrow and
% long). Printing this onto the a0 printer chops the right hand edge.
% However, 'psnup' can save the day, reorienting the text so that the
% poster prints lengthways down an a0 portrait bounding box.
%
% 'psnup -w85cm -h119cm -f poster_from_dvips.ps poster_in_landscape.ps'

\documentclass[a0]{a0poster}
% You might find the 'draft' option to a0 poster useful if you have
% lots of graphics, because they can take some time to process and
% display. (\documentclass[a0,draft]{a0poster})

\pagestyle{empty}
\renewcommand{\d}{\mathrm{d}}
\newcommand{\sgn}[1]{\mathop{\mathrm{sgn}}#1}
\newcommand{\bu}{\mathbf{u}}
\newcommand{\bx}{\mathbf{x}}
\newcommand{\br}{\mathbf{r}}
\newcommand{\ds}{\mathrm{d}s}
\newcommand{\ie}{\textit{i.e.}}
\setcounter{secnumdepth}{0}
\newcommand{\comment}[1]{}

% The textpos package is necessary to position textblocks at arbitary 
% places on the page.
\usepackage[absolute]{textpos}
% Graphics to include graphics. Times is nice on posters, but you
% might want to switch it off and go for CMR fonts.
\usepackage[final]{graphics}
\usepackage{wrapfig,helvet}
\usepackage{amsmath}

% These colours are tried and tested for titles and headers. Don't
% over use color!
\usepackage{color}
\definecolor{DarkBlue}{rgb}{0.1,0.1,0.5}
\definecolor{Red}{rgb}{0.9,0.0,0.1}
\definecolor{headingcol}{rgb}{0.5,0.7,1}
%\definecolor{boxcol}{rgb}{0.3,0.8,0.1}

% see documentation for a0poster class for the size options here
\let\Textsize\normalsize
\def\Head#1{
  \noindent\hbox to \hsize{\hfil{\LARGE\color{DarkBlue}\sf #1}}\bigskip}
\def\LHead#1{\noindent{\LARGE\color{DarkBlue}\sf #1}\bigskip}
\def\Subhead#1{\noindent{\large\color{DarkBlue}\sf #1}\bigskip}
\def\Title#1{\noindent{\VeryHuge\color{Red}\bf\sf #1}}

\TPGrid[40mm,40mm]{23}{12}  % 3 cols of width 7 plus 2 gaps width 1

\parindent=0pt
\parskip=0.5\baselineskip

\makeatletter                         %Needed to include code in main file
\renewcommand\@maketitle{             %
\null			              %Sets position marker
{
\color{headingcol}\sffamily\VERYHuge  %Set title font and colour
\@title \par}%
\vskip 0.6em%
{
\color{white}\sffamily\LARGE	      %Set author font and colour
\lineskip .5em%
\begin{tabular}[t]{l}%
\@author
\end{tabular}\par}%
\vskip 1cm
\par
}
\makeatother

\title{Shufl - addressing cold start in music recommendation}

\author{Wiktor Grajkowski and Ioannis Gakos\\ University College London}

\begin{document}
  %----------------------------------------------------------------------%
  %           Title bar: across all 21 columns                           %
  %----------------------------------------------------------------------%
  \begin{textblock}{23}(0,0)
  \vspace*{-48mm}\hspace*{-42mm}%
  \includegraphics{ucl_bar_black.eps}
  \begin{minipage}{1191mm}		%Minipage for title contents
  \vspace{-20cm}
  \maketitle
  \end{minipage}
  \end{textblock}

  %%%%%%%%%%%%%%%%%% Will need to shift all other content down a bit %%%%%

  %----------------------------------------------------------------------%
  %           First column.                                              %
  %----------------------------------------------------------------------%
  \begin{textblock}{7}(0,2.4)
    \Head{Introduction}
    \sf % Selects sans serif family: part of the UCL corporate image!
    Our goal is to build a music recommendation system using a Convolutional
    Neural Network (CNN). CNNs have been widely used in applications such as
    image recognition and recommendation systems. The promiment shift of the
    music industry towards the Web, has made music recommendation a rather
    relevant problem whose solution could radically improve users' experience.
    However, in the absence of usage data, existing methods such as
    collaborative filtering fall short in taking effective decisions for new
    and unpopular music content. [1]
    \\ \\
    Shufl's design is based on recent work of Sander Dieleman et al. on music
    recommendation [1] using deep CNNs and on Dieleman's post on the
    implementation details of such a CNN built during his internship at
    Spotify. Our main objective is to build a system that addresses the cold
    start problem for both new users and music content. Users give as sole
    input a single preferred track based on which a shuffled playist with
    relevant music content is generated. Newly imported music content is
    classified based on its frequency spectrum and the already existing ground
    truth data, without using any usage related feedback. In order to train
    the CNN model, the MagnaTagATune open dataset will be used, which contains
    26,000 of 29 seconds user annotated audio samples.

    \bigskip
    \hrule
  \end{textblock}

  \begin{textblock}{7}(0,5.9)
    \Head{The Problem}

    \sf 
    It is worth fiddling around a bit with positioning of the text blocks to
    get the spacing even. I like a vertical gap of about 0.4 ``block units''
    between the horizontal bar at the end of one block and the beginning of the
    next. There are contruction lines at the end of the \TeX\ file to help with
    this.

    \bigskip
    \hrule
  \end{textblock}

  \begin{textblock}{7}(0,8.70)
    \Head{Dataset}
    \sf
    In order to train the CNN, we are using the MagnaTagATune dataset, which
    was made available by the Magnatune label for the research community. The
    data was collected using the TagATune game where users annotated audio
    tracks with audio relevant tags.
    \\ \\
    The dataset consists of approximately 26,000 of 29 seconds music clips
    encoded in 16 kHz, 32kbps, mono mp3, generously contributed by John
    Buckman, the founder of every MIR researcher's favorite label Magnatune.
    Each of them annotated with a combination of 188 tags such as "orchestral",
    "orchestra", "punk", "slow", "blues", "rock" etc. It also contains music
    similarity annotations in the form of triples where given a triple of songs
    (A, B, C), metrics of how many players have flagged the song A, B or C as
    most different from the others.

    \bigskip
    \hrule
  \end{textblock}

  %----------------------------------------------------------------------%
  %           Second column.                                             %
  %----------------------------------------------------------------------%
  \begin{textblock}{7}(8,2.4)
    \Head{Architecture}
    \sf
    Our system needs to be able to suggest songs similar to that provided by
    the user, based only on its audio sample.

    To achieve this goal we first build a ground truth model using 
    MagnaTagATune dataset. Each song in the database is annotated by users with
    multiple tags that we treat as "bag of words" meaning only the presence and
    count of a tag matters and not its position. We will run word2vec algorithm
    using gensim Python toolkit on this dataset to produce latent vecotr
    representation of each song.

    We will then build a Convolutional Neural Network taking frequency spectrum
    of an audio sample as input and outputing latent vector representation. The
    Network will be trained to minimize the error with the ground truth model.

    \bigskip
    \hrule
  \end{textblock}

  \begin{textblock}{7}(8,5.25)

    \Head{Evaluation}

    \sf
    Of course, the principal reason for choosing \LaTeX\ is its ability with
    equations:  
    \[ 
       U_\mathrm{doublet} = \frac{mg}{2\pi\mu a}\left( \int_0^\infty \left\{ 1
           - \frac{2\sinh^2{s} - 2s^2}{\sinh{2s}+2s}\right\}\,\ds
       \right)^{-1} \approx \frac{1.55mg}{6\pi\mu a}, \] 
    but it's equally easy to include tables: 
    \begin{center} 
    \begin{tabular}{cccccccccccr}
    \hline
      && \multicolumn{2}{c}{$U_1$}  && \multicolumn{2}{c}{$U_2$} 
      && \multicolumn{2}{c}{$U_3$} & $U_3$ \\ 
    $L$ &&    MR   &   SD   &&   MR   &   SD   &&   MR    &   SD & error \\ 
    \hline
    2.01 &&0.65528 &0.64739 &&0.63461 &0.62691 &&0.00498 &0.00451 & 9\%\\ 
    2.10 &&0.73857 &0.73126 &&0.59718 &0.58784 &&0.03517 &0.02570 &27\%\\ 
    2.50 &&0.87765 &0.87482 &&0.49545 &0.48829 &&0.07393 &0.05853 &21\%\\ 
    3.00 &&0.93905 &0.93806 &&0.41694 &0.41356 &&0.07824 &0.06970 &11\%\\ 
    4.00 &&0.97964 &0.97945 &&0.31859 &0.31774 &&0.06925 &0.06639 & 4\%\\ 
    6.00 &&0.99581 &0.99579 &&0.21586 &0.21575 &&0.05078 &0.05019 & 1\%\\ 
    \hline
    \end{tabular} 
    \end{center}
    and, of course, images:
    \begin{center}
    \rotatebox{-90}{\scalebox{2.22}{\includegraphics{fig2.eps}}}
    \end{center}

    \bigskip
    \hrule
  \end{textblock}

  %----------------------------------------------------------------------%
  %           Third column.                                              %
  %----------------------------------------------------------------------%
  \begin{textblock}{7}(16,2.4)

    \Head{Possible Extensions}
    \sf

    \Subhead{User feedback}

    One of the possible extensions we could investigate is using user feedback
    provided through a simple interface in order to enhance the recommendation
    results. For example, there might be cases where the next proposed track
    does not satisfy the user's preferences. Having a way to collect such
    feedback could help the system fine tune music similarity data based on
    triples, including the previous, the current and the next proposed tracks.
    Though as Dieleman references on his post, this type of feedback tends to
    be very noisy, thus we are not certain whether or not such a feature will
    improve our results.
    
    \bigskip

    \Subhead{Million Song Dataset (MSD)}

    The Million Song Dataset is a freely-available collection of audio features
    and metadata for a million contemporary popular music tracks. This is
    rather big in contrast to MagnaTagATune. Depending on the evaluation
    results, this dataset might prove useful to establish a more intelligent
    model where a greater variety of filters are learnt. However, in the
    interest of time, processing such a huge dataset in a traditional fashion
    is not an option. If necessary, using Amazon's Web services such as EMR
    (MapReduce, Spark) to process the MSD is definitely a solution.

    \bigskip
    \hrule
  \end{textblock}


  \begin{textblock}{7}(16,6.85)

  \Head{Discussion and Conclusions}

  \sf
  Etiam sit amet nisi. Lorem ipsum dolor sit amet, consectetuer adipiscing elit.
  Phasellus pharetra lacus. Aliquam erat volutpat. Donec leo. Mauris dapibus,
  magna sed hendrerit volutpat, massa magna euismod metus, vel gravida purus
  odio eget neque. Proin nibh turpis, commodo at, viverra sed, auctor vel,
  turpis. Mauris massa lacus, malesuada at, consectetuer at, condimentum non,
  nibh. Sed laoreet, lorem non tristique sodales, mauris nisi molestie dolor,
  ac volutpat nisl augue id nibh. Mauris orci. Donec non lacus. Duis ut arcu.
  Aliquam sed lacus eget dui sollicitudin pellentesque. Nunc lacus nisi, semper
  nec, pellentesque non, dapibus sollicitudin, metus. Aenean ac enim et est
  sollicitudin ultricies. Integer vitae magna vitae velit condimentum dapibus.
  Aenean nec sem ut massa condimentum faucibus. 

  Proin dignissim nunc in nulla. Vivamus non leo. Nulla ultrices tempor dui.
  Curabitur nec metus. Aliquam sed libero. Cras orci odio, molestie a, suscipit
  in, placerat vel, nunc. Vestibulum congue, nunc in faucibus scelerisque, ante
  tortor dapibus nibh, eu tristique diam urna ac magna. Proin cursus. Morbi
  quam ligula, fermentum vel, dapibus sit amet, euismod nec, justo. Suspendisse
  potenti. Nulla eu elit. Pellentesque quam est, pretium ac, suscipit sed,
  viverra id, sapien.
  Donec tempor semper tortor. Nunc vulputate. Aliquam vitae metus ut sem
  euismod accumsan. Duis tincidunt lacus sed ipsum. Class aptent taciti
  sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos.
  Quisque nec nisl at erat ornare tempus. Etiam eros odio, ultricies non,
  hendrerit et, vestibulum in, felis. Vivamus gravida. 

  \begin{itemize}
    \item First concluding point; we expected this to be so because of the
      contruction of the argument and blah. 
    \item Second concluding point: this one is counterintuitive but we can
      justify it by reference to the extended discussion above.
    \item Third and \textcolor{Red}{most important concluding point}: this iss
       the one we're excited about.
  \end{itemize}

  \vspace*{4mm} % Sometimes you will have to fudge the final spacing.
  \bigskip
  \hrule
  \end{textblock}

  %----------------------------------------------------------------------%
  %            Construction lines                                        %

  %\begin{textblock}{23}(0,2)\rule{\textwidth}{0.1mm}\end{textblock}
  % Shows where the bottom of the header bar should fall.

  %\begin{textblock}{23}(0,2.4)\rule{\textwidth}{0.1mm}\end{textblock}
  % Shows where the top of each column should start.

  %\begin{textblock}{23}(0,12)\rule{\textwidth}{0.1mm}\end{textblock}
  % Shows where the bottom of the lowest block in each column should end

  %\begin{textblock}{1.5}(6,4.12)\rule{\textwidth}{0.1mm}\end{textblock}
  %\begin{textblock}{1.5}(6,4.52)\rule{\textwidth}{0.1mm}\end{textblock}
  % Used to find the base of the first block and thus the top of the second.

  %\begin{textblock}{1.5}(14,4.85)\rule{\textwidth}{0.1mm}\end{textblock}
  %\begin{textblock}{1.5}(14,5.25)\rule{\textwidth}{0.1mm}\end{textblock}
  % Same purpose but in the second column.

  %\begin{textblock}{1.5}(15,6.05)\rule{\textwidth}{0.1mm}\end{textblock}
  %\begin{textblock}{1.5}(15,6.45)\rule{\textwidth}{0.1mm}\end{textblock}
  % Same purpose but in the third column.

\end{document}
